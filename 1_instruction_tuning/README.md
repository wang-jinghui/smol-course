# Instruction Tuning

æœ¬æ¨¡å—å°†æŒ‡å¯¼æ‚¨è¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜è¯­è¨€æ¨¡å‹çš„æ“ä½œã€‚æŒ‡ä»¤è°ƒä¼˜æ¶‰åŠé€šè¿‡å¯¹ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†è¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒï¼Œä½¿é¢„è®­ç»ƒæ¨¡å‹é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚è¿™ä¸€è¿‡ç¨‹æœ‰åŠ©äºæ¨¡å‹åœ¨ç›®æ ‡ä»»åŠ¡ä¸Šæé«˜æ€§èƒ½ã€‚

åœ¨æœ¬æ¨¡å—ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ä¸¤ä¸ªä¸»é¢˜ï¼š1) èŠå¤©æ¨¡æ¿ã€2) ç›‘ç£å¾®è°ƒã€‚

## 1ï¸âƒ£ Chat Templates

èŠå¤©æ¨¡æ¿æ„å»ºäº†ç”¨æˆ·ä¸AIæ¨¡å‹ä¹‹é—´çš„äº¤äº’ç»“æ„ï¼Œç¡®ä¿å›å¤çš„ä¸€è‡´æ€§å’Œä¸Šä¸‹æ–‡æ°å½“æ€§ã€‚å®ƒä»¬åŒ…æ‹¬ç³»ç»Ÿæç¤ºå’ŒåŸºäºè§’è‰²çš„æ¶ˆæ¯ç­‰ç»„ä»¶ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…èŠå¤©æ¨¡æ¿[Chat Templates](./chat_templates.md)ã€‚

## 2ï¸âƒ£ Supervised Fine-Tuning

ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ˜¯å°†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹é€‚åº”ç‰¹å®šä»»åŠ¡çš„å…³é”®è¿‡ç¨‹ã€‚å®ƒæ¶‰åŠä½¿ç”¨å¸¦æœ‰æ ‡ç­¾çš„ç¤ºä¾‹åœ¨ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚æœ‰å…³SFTçš„è¯¦ç»†æŒ‡å—ï¼ŒåŒ…æ‹¬å…³é”®æ­¥éª¤å’Œæœ€ä½³å®è·µï¼Œè¯·å‚é˜…ç›‘ç£å¾®è°ƒ[Supervised Fine-Tuning](./supervised_fine_tuning.md)ã€‚

## Exercise Notebooks

| Title | Description | Exercise | Link | Colab |
|-------|-------------|----------|------|-------|
| Chat Templates | å­¦ä¹ å¦‚ä½•ä½¿ç”¨SmolLM2ä¸­çš„èŠå¤©æ¨¡æ¿ï¼Œå¹¶å°†æ•°æ®é›†å¤„ç†ä¸ºchatmlæ ¼å¼ | ğŸ¢ Convert the `HuggingFaceTB/smoltalk` dataset into chatml format <br> ğŸ• Convert the `openai/gsm8k` dataset into chatml format | [Notebook](./notebooks/chat_templates_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/chat_templates_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> |
| Supervised Fine-Tuning | å­¦ä¹ å¦‚ä½•ä½¿ç”¨SFTTrainerå¾®è°ƒSmolLM2 | ğŸ¢ Use the `HuggingFaceTB/smoltalk` dataset<br>ğŸ• Try out the `bigcode/the-stack-smol` dataset<br>ğŸ¦ Select a dataset for a real world use case | [Notebook](./notebooks/sft_finetuning_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/sft_finetuning_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> |

## References

- [Transformers documentation on chat templates](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Script for Supervised Fine-Tuning in TRL](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)
- [`SFTTrainer` in TRL](https://huggingface.co/docs/trl/main/en/sft_trainer)
- [Direct Preference Optimization Paper](https://arxiv.org/abs/2305.18290)
- [Supervised Fine-Tuning with TRL](https://huggingface.co/docs/trl/main/en/tutorials/supervised_finetuning)
- [How to fine-tune Google Gemma with ChatML and Hugging Face TRL](https://www.philschmid.de/fine-tune-google-gemma)
- [Fine-tuning LLM to Generate Persian Product Catalogs in JSON Format](https://huggingface.co/learn/cookbook/en/fine_tuning_llm_to_generate_persian_product_catalogs_in_json_format)
