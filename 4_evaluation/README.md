# Evaluation

è¯„ä¼°æ˜¯å¼€å‘å’Œéƒ¨ç½²è¯­è¨€æ¨¡å‹ä¸­çš„ä¸€ä¸ªå…³é”®æ­¥éª¤ã€‚å®ƒæœ‰åŠ©äºæˆ‘ä»¬äº†è§£æ¨¡å‹åœ¨ä¸åŒèƒ½åŠ›ä¸Šçš„è¡¨ç°æƒ…å†µï¼Œå¹¶è¯†åˆ«å‡ºéœ€è¦æ”¹è¿›çš„é¢†åŸŸã€‚æœ¬æ¨¡å—æ—¢åŒ…å«æ ‡å‡†åŸºå‡†æµ‹è¯•ï¼Œä¹Ÿæ¶µç›–ç‰¹å®šé¢†åŸŸçš„è¯„ä¼°æ–¹æ³•ï¼Œä»¥å…¨é¢è¯„ä¼°æ‚¨çš„smolæ¨¡å‹ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨[`lighteval`](https://github.com/huggingface/lighteval)ï¼Œè¿™æ˜¯Hugging Faceå¼€å‘çš„ä¸€æ¬¾å¼ºå¤§çš„è¯„ä¼°åº“ï¼Œå®ƒä¸Hugging Faceç”Ÿæ€ç³»ç»Ÿæ— ç¼é›†æˆã€‚æƒ³è¦æ·±å…¥äº†è§£è¯„ä¼°æ¦‚å¿µå’Œæœ€ä½³å®è·µï¼Œè¯·æŸ¥é˜…è¯„ä¼°[guidebook](https://github.com/huggingface/evaluation-guidebook)ã€‚

## Module Overview 

ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°ç­–ç•¥ä¼šè€ƒå¯Ÿæ¨¡å‹æ€§èƒ½çš„å¤šä¸ªæ–¹é¢ã€‚æˆ‘ä»¬è¯„ä¼°ç‰¹å®šä»»åŠ¡çš„èƒ½åŠ›ï¼Œå¦‚é—®ç­”å’Œæ‘˜è¦ç”Ÿæˆï¼Œä»¥äº†è§£æ¨¡å‹å¤„ç†ä¸åŒç±»å‹é—®é¢˜çš„èƒ½åŠ›ã€‚æˆ‘ä»¬é€šè¿‡è¿è´¯æ€§å’Œäº‹å®å‡†ç¡®æ€§ç­‰å› ç´ æ¥è¡¡é‡è¾“å‡ºè´¨é‡ã€‚å®‰å…¨æ€§è¯„ä¼°æœ‰åŠ©äºè¯†åˆ«æ½œåœ¨çš„æœ‰å®³è¾“å‡ºæˆ–åè§ã€‚æœ€åï¼Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†æµ‹è¯•éªŒè¯äº†æ¨¡å‹åœ¨ç›®æ ‡é¢†åŸŸä¸­çš„ä¸“ä¸šçŸ¥è¯†ã€‚


### 1ï¸âƒ£ [Automatic Benchmarks](./automatic_benchmarks.md)
å­¦ä¹ ä½¿ç”¨æ ‡å‡†åŒ–åŸºå‡†å’ŒæŒ‡æ ‡æ¥è¯„ä¼°æ‚¨çš„æ¨¡å‹ã€‚æˆ‘ä»¬å°†æ¢è®¨å¸¸è§çš„åŸºå‡†ï¼Œå¦‚`MMLU`å’Œ`TruthfulQA`ï¼Œç†è§£å…³é”®çš„è¯„ä¼°æŒ‡æ ‡å’Œè®¾ç½®ï¼Œå¹¶ä»‹ç»å¯é‡å¤è¯„ä¼°çš„æœ€ä½³å®è·µã€‚

### 2ï¸âƒ£ [Custom Domain Evaluation](./custom_evaluation.md)
äº†è§£å¦‚ä½•åˆ›å»ºé€‚åˆæ‚¨ç‰¹å®šç”¨ä¾‹çš„è¯„ä¼°æµç¨‹ã€‚æˆ‘ä»¬å°†é€æ­¥æŒ‡å¯¼æ‚¨è®¾è®¡è‡ªå®šä¹‰è¯„ä¼°ä»»åŠ¡ã€å®ç°ä¸“é—¨æŒ‡æ ‡ï¼Œä»¥åŠæ„å»ºç¬¦åˆæ‚¨éœ€æ±‚çš„è¯„ä¼°æ•°æ®é›†ã€‚

### 3ï¸âƒ£ [Domain Evaluation Project](./project/README.md)
è·Ÿéšä¸€ä¸ªå®Œæ•´çš„æ„å»ºç‰¹å®šé¢†åŸŸè¯„ä¼°æµç¨‹çš„ä¾‹å­ã€‚æ‚¨å°†å­¦ä¹ å¦‚ä½•ç”Ÿæˆè¯„ä¼°æ•°æ®é›†ï¼Œä½¿ç”¨`Argilla`è¿›è¡Œæ•°æ®æ ‡æ³¨ï¼Œåˆ›å»ºæ ‡å‡†åŒ–æ•°æ®é›†ï¼Œä»¥åŠä½¿ç”¨`LightEval`è¯„ä¼°æ¨¡å‹ã€‚

### Exercise 
- ğŸ¢ ä½¿ç”¨åŒ»å­¦é¢†åŸŸä»»åŠ¡æ¥è¯„ä¼°æ¨¡å‹
- ğŸ• ä½¿ç”¨ä¸åŒçš„MMLUä»»åŠ¡åˆ›å»ºä¸€ä¸ªæ–°çš„é¢†åŸŸè¯„ä¼°
- ğŸ¦ ä¸ºæ‚¨çš„é¢†åŸŸåˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰è¯„ä¼°ä»»åŠ¡

## Resources

- [Evaluation Guidebook](https://github.com/huggingface/evaluation-guidebook) - Comprehensive guide to LLM evaluation
- [LightEval Documentation](https://github.com/huggingface/lighteval) - Official docs for the LightEval library
- [Argilla Documentation](https://docs.argilla.io) - Learn about the Argilla annotation platform
- [MMLU Paper](https://arxiv.org/abs/2009.03300) - Paper describing the MMLU benchmark
- [Creating a Custom Task](https://github.com/huggingface/lighteval/wiki/Adding-a-Custom-Task)
- [Creating a Custom Metric](https://github.com/huggingface/lighteval/wiki/Adding-a-New-Metric)
- [Using existing metrics](https://github.com/huggingface/lighteval/wiki/Metric-List)